{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/0nbwk8050kn6p836qqxnct3c0000gn/T/ipykernel_3284/812677177.py:2: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  Y=pd.Series()\n"
     ]
    }
   ],
   "source": [
    "X=pd.DataFrame()\n",
    "Y=pd.Series()\n",
    "\n",
    "x_train=np.array([[1,2,3,4],[1,2,3,4]])\n",
    "x_test=np.array([[4,5,6,7],[4,5,6,7]])\n",
    "\n",
    "y_train=np.array([1,2,3,4])\n",
    "y_test=np.array([1,3,4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionDataset(Dataset):\n",
    "\n",
    "    def __init__(self,x_data,y_data) -> None:\n",
    "        self.x_data=x_data\n",
    "        self.y_data=y_data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data),len(self.y_data)\n",
    "    \n",
    "x_train_tensor=torch.from_numpy(x_train).float()\n",
    "y_train_tensor=torch.from_numpy(x_test).float()\n",
    "\n",
    "x_test_tensor=torch.from_numpy(x_test).float()\n",
    "y_test_tensor=torch.from_numpy(y_test).float()\n",
    "\n",
    "train_data_final=RegressionDataset(x_train_tensor,y_train_tensor)\n",
    "test_data_final=RegressionDataset(x_test_tensor,y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelInitiation:\n",
    "    epochs:int=150\n",
    "    batch_size_train:int=64\n",
    "    batch_size_test:int=1\n",
    "    lr:float=0.001\n",
    "    numerical_features:int=len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(dataset=train_data_final,batch_size=ModelInitiation.batch_size_train)\n",
    "\n",
    "test_dataloader=DataLoader(dataset=test_data_final,batch_size=ModelInitiation.batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining neaural networks architecture\n",
    "\n",
    "class Regression(nn.Module):\n",
    "    def __init__(self, num_features) -> None:\n",
    "        super(Regression,self).__init__()\n",
    "\n",
    "        self.layer1=nn.Linear(num_features,32)\n",
    "        self.layer2= nn.Linear(32,64)\n",
    "        self.layer3= nn.Linear(64,128)\n",
    "        self.layer4=nn.Linear(128,256)\n",
    "        self.layer_out= nn.Linear(256,1)\n",
    "\n",
    "        self.relu= nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        x1=self.relu(self.layer1(inputs))\n",
    "        x2=self.relu(self.layer2(x1))\n",
    "        x3=self.relu(self.layer3(x2))\n",
    "        x4=self.relu(self.layer4(x3))\n",
    "        x5_out=self.layer_out(x4)\n",
    "        return x5_out\n",
    "    \n",
    "    def predict(self,test_inputs):\n",
    "        x1=self.relu(self.layer1(test_inputs))\n",
    "        x2=self.relu(self.layer2(x1))\n",
    "        x3=self.relu(self.layer3(x2))\n",
    "        x4=self.relu(self.layer4(x3))\n",
    "        x5_out=self.layer_out(x4)\n",
    "        return x5_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "model=Regression(ModelInitiation.numerical_features)\n",
    "model.to(device=device)\n",
    "\n",
    "#add the loss function and add the optimized\n",
    "\n",
    "criterion=nn.MSELoss()\n",
    "optimizers=optim.Adam(model.parameters(),lr=ModelInitiation.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([], size=(32, 0), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1685, -0.0643, -0.1151,  ...,  0.0560, -0.1711,  0.0588],\n",
      "        [-0.0771,  0.0433,  0.0933,  ...,  0.0943, -0.0027,  0.0179],\n",
      "        [ 0.1509,  0.0537,  0.0112,  ...,  0.0377, -0.0623, -0.1110],\n",
      "        ...,\n",
      "        [ 0.0682,  0.1567, -0.0126,  ...,  0.0127, -0.1544,  0.1108],\n",
      "        [-0.0901,  0.0437,  0.1643,  ..., -0.1622,  0.0417, -0.0633],\n",
      "        [-0.0425, -0.1748, -0.0762,  ...,  0.0060,  0.0112, -0.0710]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1432,  0.0358,  0.0811,  0.1567, -0.1375,  0.0114,  0.0565, -0.1005,\n",
      "         0.1318,  0.0896, -0.1072, -0.0968,  0.1203, -0.0676, -0.0186,  0.1481,\n",
      "        -0.1152, -0.0264,  0.1416, -0.0430, -0.0689,  0.0846,  0.1520,  0.0072,\n",
      "        -0.0465, -0.0160, -0.1556, -0.1074, -0.0595,  0.1649, -0.0624, -0.0744,\n",
      "         0.1492, -0.0871,  0.1299, -0.0597,  0.1396,  0.0222,  0.0485, -0.1654,\n",
      "         0.1348,  0.0645, -0.1061,  0.1055,  0.1385, -0.1245, -0.0218,  0.1656,\n",
      "         0.0410, -0.0233,  0.1052,  0.1439, -0.1265, -0.0954,  0.0887, -0.1456,\n",
      "         0.1159,  0.0336,  0.0725, -0.0786, -0.0533,  0.0131, -0.0447, -0.0095],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0062, -0.0758, -0.0664,  ..., -0.0439,  0.0275, -0.0647],\n",
      "        [-0.1129, -0.0022,  0.1070,  ...,  0.0219,  0.1183,  0.1201],\n",
      "        [-0.0316,  0.1165, -0.0935,  ...,  0.1219, -0.0085, -0.0488],\n",
      "        ...,\n",
      "        [ 0.0759, -0.0429, -0.0559,  ..., -0.0023, -0.0943,  0.0290],\n",
      "        [ 0.0225,  0.1016, -0.0181,  ...,  0.0589,  0.1072,  0.0718],\n",
      "        [ 0.0292, -0.0973,  0.0562,  ...,  0.0885,  0.1136,  0.0729]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0051, -0.0473, -0.0053,  0.1123, -0.0525,  0.0329,  0.1227, -0.0552,\n",
      "         0.0675,  0.0951,  0.0712, -0.0467, -0.0421, -0.0700, -0.0696,  0.0451,\n",
      "         0.0264, -0.0515,  0.1243, -0.0230, -0.1093, -0.1082,  0.1185, -0.0327,\n",
      "        -0.0350,  0.0695, -0.0288, -0.0634,  0.0766, -0.0512, -0.0216, -0.0839,\n",
      "         0.0986, -0.1213, -0.0286, -0.1066,  0.0745,  0.1199,  0.1006, -0.0958,\n",
      "        -0.0844,  0.0991,  0.1014, -0.1194,  0.0280, -0.0998,  0.0855, -0.0412,\n",
      "        -0.1030,  0.0773,  0.0682,  0.0127,  0.0133,  0.0658, -0.0567, -0.0318,\n",
      "        -0.1161,  0.1180, -0.0234,  0.1102, -0.0796,  0.0700,  0.0182,  0.0481,\n",
      "         0.0233,  0.1010,  0.1005, -0.1223, -0.0952, -0.0352,  0.0197,  0.0242,\n",
      "        -0.0164,  0.1098, -0.0468, -0.1235,  0.0802,  0.0761, -0.0238,  0.0791,\n",
      "         0.0955, -0.0587,  0.0678,  0.0333,  0.0864,  0.0895, -0.0273,  0.1244,\n",
      "        -0.0908, -0.1002,  0.0786,  0.0867,  0.0046, -0.0294,  0.0632,  0.0252,\n",
      "         0.0838, -0.0539, -0.0780,  0.0307, -0.0701,  0.0896,  0.0695, -0.0738,\n",
      "         0.0441,  0.0708, -0.0857,  0.0694, -0.0743, -0.0080,  0.1125, -0.0823,\n",
      "        -0.0455,  0.0872, -0.0709,  0.0032,  0.1013, -0.1054,  0.0388, -0.0311,\n",
      "        -0.0548,  0.0503, -0.1232,  0.0629,  0.0688, -0.0626,  0.0250, -0.0389],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0751, -0.0851,  0.0140,  ..., -0.0402,  0.0587, -0.0276],\n",
      "        [ 0.0755, -0.0313, -0.0850,  ...,  0.0169, -0.0750,  0.0594],\n",
      "        [-0.0022, -0.0613,  0.0292,  ...,  0.0437,  0.0304,  0.0349],\n",
      "        ...,\n",
      "        [ 0.0698, -0.0018, -0.0322,  ...,  0.0783,  0.0834,  0.0449],\n",
      "        [ 0.0402, -0.0438,  0.0093,  ...,  0.0126,  0.0465,  0.0696],\n",
      "        [ 0.0574,  0.0263, -0.0882,  ..., -0.0278,  0.0527,  0.0686]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0598,  0.0877,  0.0796,  0.0728, -0.0647, -0.0233,  0.0010, -0.0221,\n",
      "        -0.0422,  0.0651,  0.0248,  0.0553,  0.0613, -0.0785, -0.0009,  0.0159,\n",
      "        -0.0609, -0.0656, -0.0376,  0.0497, -0.0447,  0.0068, -0.0597,  0.0057,\n",
      "        -0.0097, -0.0071, -0.0351,  0.0779, -0.0359, -0.0100, -0.0721,  0.0274,\n",
      "        -0.0170, -0.0650,  0.0882, -0.0343, -0.0421, -0.0180, -0.0795,  0.0097,\n",
      "        -0.0303,  0.0769, -0.0152, -0.0172, -0.0145, -0.0573,  0.0168,  0.0864,\n",
      "        -0.0662, -0.0037,  0.0083,  0.0879,  0.0831,  0.0583, -0.0692,  0.0344,\n",
      "         0.0845, -0.0295,  0.0810,  0.0096,  0.0360,  0.0388, -0.0588, -0.0503,\n",
      "         0.0675,  0.0654, -0.0701,  0.0066,  0.0830,  0.0844, -0.0786,  0.0827,\n",
      "         0.0395, -0.0839, -0.0175, -0.0638, -0.0049, -0.0351, -0.0145,  0.0295,\n",
      "        -0.0390,  0.0622,  0.0684, -0.0527, -0.0397,  0.0007, -0.0853, -0.0661,\n",
      "        -0.0883, -0.0850,  0.0218,  0.0707,  0.0125, -0.0500,  0.0271,  0.0760,\n",
      "         0.0670, -0.0313, -0.0034, -0.0705,  0.0105, -0.0837,  0.0795, -0.0556,\n",
      "        -0.0732, -0.0615,  0.0119,  0.0589, -0.0665,  0.0180, -0.0104,  0.0839,\n",
      "        -0.0813, -0.0681, -0.0235,  0.0057, -0.0822,  0.0544,  0.0698, -0.0075,\n",
      "         0.0854,  0.0305,  0.0798, -0.0043,  0.0631,  0.0808, -0.0028,  0.0614,\n",
      "         0.0102,  0.0632, -0.0554,  0.0194,  0.0284,  0.0258, -0.0846, -0.0870,\n",
      "        -0.0292, -0.0636, -0.0650,  0.0120,  0.0855,  0.0519, -0.0284,  0.0582,\n",
      "        -0.0829,  0.0077,  0.0399,  0.0386, -0.0303, -0.0755, -0.0528,  0.0539,\n",
      "        -0.0495, -0.0348, -0.0249,  0.0325, -0.0230, -0.0019, -0.0137, -0.0222,\n",
      "        -0.0360,  0.0717, -0.0447, -0.0092,  0.0040,  0.0179, -0.0148, -0.0700,\n",
      "         0.0588, -0.0820, -0.0584,  0.0577, -0.0462, -0.0256, -0.0761, -0.0161,\n",
      "        -0.0561, -0.0709, -0.0157, -0.0227,  0.0602, -0.0520, -0.0609, -0.0488,\n",
      "        -0.0771,  0.0104, -0.0644,  0.0668, -0.0193, -0.0778, -0.0780,  0.0086,\n",
      "        -0.0738, -0.0474,  0.0791, -0.0672, -0.0350, -0.0249,  0.0813, -0.0397,\n",
      "        -0.0200,  0.0075, -0.0179,  0.0400,  0.0636,  0.0233,  0.0262, -0.0274,\n",
      "        -0.0310,  0.0799,  0.0180,  0.0432,  0.0572, -0.0593, -0.0854,  0.0745,\n",
      "        -0.0547,  0.0441,  0.0358, -0.0358, -0.0848,  0.0189, -0.0056, -0.0825,\n",
      "        -0.0786,  0.0533, -0.0269,  0.0543, -0.0061, -0.0831, -0.0451,  0.0056,\n",
      "         0.0044, -0.0030, -0.0818, -0.0765,  0.0353, -0.0518, -0.0433, -0.0406,\n",
      "        -0.0299, -0.0061,  0.0093,  0.0129,  0.0014,  0.0444,  0.0151,  0.0008,\n",
      "         0.0740,  0.0177,  0.0332, -0.0362,  0.0658,  0.0088, -0.0755,  0.0349],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.0414e-02, -4.5856e-02,  2.0152e-02,  4.6648e-02,  3.6094e-02,\n",
      "          3.4000e-03,  2.1943e-02, -2.0731e-02,  4.4964e-02,  1.0140e-02,\n",
      "          4.3780e-02, -2.3307e-03, -6.0806e-02, -5.3588e-02,  6.1922e-02,\n",
      "          1.4821e-02,  4.9210e-03,  8.0667e-03,  4.3761e-02,  2.9418e-02,\n",
      "          2.9176e-02,  3.9016e-03, -4.5772e-02,  8.2120e-03,  6.1062e-02,\n",
      "          1.7005e-02, -1.4524e-02, -3.8026e-02,  6.5099e-03, -2.0434e-02,\n",
      "          5.9886e-02, -1.5877e-03, -2.7885e-02,  5.5447e-02,  3.5869e-02,\n",
      "          6.0486e-02,  5.5861e-02, -3.2018e-02, -6.8450e-03,  2.0663e-02,\n",
      "         -5.4904e-02, -5.4975e-02, -4.1434e-02, -6.1686e-02, -6.1458e-02,\n",
      "         -4.3433e-02,  1.8815e-03, -1.6936e-02, -2.0164e-02,  1.1992e-02,\n",
      "          8.2773e-04, -9.2930e-04, -5.1261e-02, -2.3954e-02,  2.7150e-03,\n",
      "          2.3742e-03, -6.0842e-02, -3.1716e-02,  1.1868e-03,  2.1002e-02,\n",
      "          1.9178e-02,  4.0383e-02, -5.3255e-02, -3.9868e-02, -2.1422e-02,\n",
      "          4.1979e-02, -4.9502e-02, -4.4304e-02, -5.1823e-04,  5.4376e-02,\n",
      "          5.2133e-02, -8.0540e-03, -3.9894e-02, -6.2050e-02, -8.5407e-04,\n",
      "          3.5269e-03, -3.9665e-02, -2.1482e-02,  4.0145e-02,  5.2005e-02,\n",
      "         -5.2584e-02,  8.4945e-03, -4.6482e-03, -2.7887e-02, -1.1244e-02,\n",
      "          1.4809e-02, -3.6778e-02, -3.9990e-02,  3.5727e-02,  2.3078e-02,\n",
      "         -1.4423e-03,  3.0572e-02,  1.2824e-02, -4.5840e-02, -1.2306e-02,\n",
      "          4.1008e-03,  9.2075e-03,  1.3078e-02,  3.3457e-02, -1.9690e-02,\n",
      "          2.8620e-02,  3.2417e-02, -3.8368e-02, -4.1234e-02, -3.4430e-02,\n",
      "         -5.5925e-02, -2.8577e-02, -2.2569e-02,  3.9995e-02,  4.3406e-02,\n",
      "          1.0155e-03,  4.8869e-02,  1.4666e-02,  1.9020e-02, -2.1412e-02,\n",
      "         -4.8481e-02,  7.1293e-03,  4.1131e-02, -4.7245e-02, -1.3740e-02,\n",
      "          8.3557e-03,  2.8353e-02,  5.0804e-02,  1.7529e-03,  4.0906e-02,\n",
      "         -4.9495e-02, -5.0338e-02, -5.2789e-02,  2.0635e-03,  2.5887e-02,\n",
      "         -1.1866e-02,  3.8152e-02,  6.2451e-02,  4.0919e-05, -2.4677e-02,\n",
      "         -6.1882e-02, -4.6712e-02,  8.9020e-05, -5.1373e-02,  2.0226e-02,\n",
      "         -5.3448e-02, -8.1491e-03, -3.7504e-02,  2.3301e-02,  1.3078e-02,\n",
      "          2.7824e-02,  6.1116e-03, -5.7661e-02, -3.2745e-02,  6.1456e-02,\n",
      "          3.9891e-02, -2.1807e-02, -3.0024e-02, -2.4491e-02, -2.6830e-02,\n",
      "          4.4017e-02,  4.4651e-02, -5.5769e-02,  6.2304e-02,  5.5472e-02,\n",
      "          2.0072e-02,  3.5381e-02, -2.3627e-02,  1.9245e-02, -2.1063e-02,\n",
      "          5.0118e-04,  4.0195e-02, -5.8227e-02, -6.7593e-04, -3.1323e-02,\n",
      "         -5.5739e-02,  3.4669e-02,  1.1174e-02, -4.7764e-02,  1.5621e-02,\n",
      "         -3.7625e-02,  4.6192e-02,  1.6781e-02, -6.2165e-02,  3.3001e-03,\n",
      "          1.8797e-02, -1.0237e-02,  5.4905e-02, -2.2487e-02,  4.7206e-02,\n",
      "          2.0015e-02, -2.7423e-02,  1.3708e-02, -5.6044e-02,  4.5611e-02,\n",
      "          4.4887e-02, -2.1384e-02, -5.2672e-02,  4.2146e-02,  6.0154e-02,\n",
      "         -9.4606e-04, -5.1732e-02,  4.9436e-02, -4.8567e-02, -4.0657e-02,\n",
      "          1.3712e-02, -3.5207e-02,  3.9738e-02, -4.6425e-02,  5.3462e-02,\n",
      "          1.3026e-02,  1.3620e-02,  3.2168e-02, -1.3249e-03,  2.6461e-02,\n",
      "          3.1047e-02,  1.9468e-02, -6.1692e-02, -8.4238e-03, -3.1016e-02,\n",
      "         -8.3530e-03, -5.2792e-02, -4.4315e-03, -3.3764e-02,  4.7873e-02,\n",
      "         -5.9346e-02, -1.0306e-03, -2.5563e-02, -2.5764e-02,  5.1732e-02,\n",
      "          2.3467e-02, -4.4253e-02,  5.7200e-02,  1.8293e-03, -4.5968e-02,\n",
      "          1.5077e-02, -2.1863e-02, -5.3230e-02,  9.5112e-03,  2.2082e-02,\n",
      "         -1.9018e-02,  3.5813e-02, -3.7669e-02, -1.4179e-02,  2.7454e-02,\n",
      "          2.3376e-02,  4.2845e-02, -4.9707e-02,  4.6703e-02, -2.8510e-02,\n",
      "          1.0053e-02, -1.7665e-02, -2.3000e-02, -3.4794e-02, -3.0940e-02,\n",
      "         -5.9409e-02, -1.1962e-02, -1.9047e-02, -1.9920e-02, -7.6773e-03,\n",
      "         -2.3746e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0045], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(1,ModelInitiation.epochs+1):\n",
    "    train_epoch_loss = 0\n",
    "    model.train()\n",
    "    for x_train_batch,y_train_batch in train_dataloader:\n",
    "        x_train_batch,y_train_batch=x_train_batch.to(device),y_train_batch.to(device)\n",
    "        print(y_train_batch.unsqueeze(1))\n",
    "        optimizers.zero_grad()\n",
    "        y_train_pred=model(x_train_batch)\n",
    "        train_loss=criterion(y_train_pred,y_train_batch.unsqueeze(1))\n",
    "        train_loss.backward()\n",
    "        optimizers.step()\n",
    "        train_epoch_loss+=train_loss.item()\n",
    "    with torch.no_grad():\n",
    "        val_epoch_loss=0\n",
    "        model.eval()\n",
    "        for x_val_batch,y_val_batch in test_dataloader:\n",
    "            y_val_pred=model(x_val_batch)\n",
    "            val_loss=criterion(y_val_pred,y_val_batch.unsqueeze(1))\n",
    "    loss_stats[\"train\"].append(train_epoch_loss/len(train_dataloader))\n",
    "    loss_stats[\"val\"].append(val_epoch_loss/len(test_dataloader))\n",
    "    print(f'Epoch: {e} | Train Loss: {train_epoch_loss/len(train_dataloader)} | Test Loss: {val_epoch_loss/len(test_dataloader)}')\n",
    "\n",
    "\n",
    "json.dump(loss_stats,open(\"train_val_loss.json\",\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_list=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X_batch,_ in test_dataloader:\n",
    "        X_batch=X_batch.to(device)\n",
    "        y_pred=model(X_batch)\n",
    "        ypred_list.append(y_pred.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RegressionDataset at 0x15c236990>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "mse=mean_squared_error(y_test,ypred_list)\n",
    "r2score=r2_score(y_test,y_pred)\n",
    "print(f\"r2: {r2score} | mse: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
